{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:29.918292Z","iopub.status.busy":"2023-04-20T14:16:29.917721Z","iopub.status.idle":"2023-04-20T14:16:38.581833Z","shell.execute_reply":"2023-04-20T14:16:38.580963Z","shell.execute_reply.started":"2023-04-20T14:16:29.918259Z"},"id":"FdEgnjGmGuzt","outputId":"53c309db-d611-4311-f3af-81b3ef52ecef","trusted":true},"outputs":[],"source":["import pathlib\n","dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n","data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n","data_dir = pathlib.Path(data_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:38.584031Z","iopub.status.busy":"2023-04-20T14:16:38.583199Z","iopub.status.idle":"2023-04-20T14:16:38.613526Z","shell.execute_reply":"2023-04-20T14:16:38.610885Z","shell.execute_reply.started":"2023-04-20T14:16:38.583987Z"},"id":"lnb17_AKGu6B","outputId":"319b7f29-e72e-40bf-fc14-da98a29d97b0","trusted":true},"outputs":[],"source":["image_count = len(list(data_dir.glob('*/*.jpg')))\n","print(image_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:38.617575Z","iopub.status.busy":"2023-04-20T14:16:38.617030Z","iopub.status.idle":"2023-04-20T14:16:39.607168Z","shell.execute_reply":"2023-04-20T14:16:39.606284Z","shell.execute_reply.started":"2023-04-20T14:16:38.617531Z"},"id":"sgB2QiYKOelS","outputId":"754d4ccd-7402-4045-94a3-a591907be6ec","trusted":true},"outputs":[],"source":["print(os.listdir(data_dir))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The dataset includes 3670 images of flowers organized into five subdirectories: dandelion, roses, tulips, daisy, and sunflowers."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:39.609297Z","iopub.status.busy":"2023-04-20T14:16:39.608352Z","iopub.status.idle":"2023-04-20T14:16:39.710653Z","shell.execute_reply":"2023-04-20T14:16:39.709879Z","shell.execute_reply.started":"2023-04-20T14:16:39.609256Z"},"id":"MVdmWS1uGu9D","outputId":"9f6e3472-5602-49f1-a5bc-5acd885eb668","trusted":true},"outputs":[],"source":["roses = list(data_dir.glob('roses/*'))\n","PIL.Image.open(str(roses[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:39.712001Z","iopub.status.busy":"2023-04-20T14:16:39.711597Z","iopub.status.idle":"2023-04-20T14:16:39.754046Z","shell.execute_reply":"2023-04-20T14:16:39.753121Z","shell.execute_reply.started":"2023-04-20T14:16:39.711932Z"},"id":"yUVtuGYcGvAb","outputId":"3b746c94-6126-4927-e42d-d60e94c3b016","trusted":true},"outputs":[],"source":["daisy = list(data_dir.glob('daisy/*'))\n","PIL.Image.open(str(daisy[2]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We resize the images in our dataset because they are of different sizes. We specify the image height and width to do this. We also specify the batch size, which is the number of images used by the model during each epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:39.755822Z","iopub.status.busy":"2023-04-20T14:16:39.755339Z","iopub.status.idle":"2023-04-20T14:16:39.760994Z","shell.execute_reply":"2023-04-20T14:16:39.759884Z","shell.execute_reply.started":"2023-04-20T14:16:39.755770Z"},"id":"K8j8HtCHG-gz","trusted":true},"outputs":[],"source":["batch_size = 32\n","img_height = 180\n","img_width = 180"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create an instance of the ImageDataGenerator class\n","datagen = ImageDataGenerator(\n","    rotation_range=20, # Randomly rotate the image between -20 to 20 degrees\n","    width_shift_range=0.2, # Shift the image horizontally by a random factor between -0.2 to 0.2\n","    height_shift_range=0.2, # Shift the image vertically by a random factor between -0.2 to 0.2\n","    shear_range=0.2, # Apply shear transformation randomly with a factor between -0.2 to 0.2\n","    zoom_range=0.2, # Randomly zoom into the image by a factor between 0.8 to 1.2\n","    horizontal_flip=True, # Randomly flip the image horizontally\n","    fill_mode='nearest' # Fill the empty pixel positions using the nearest pixels\n",")\n","\n","# Example usage: load images from a directory\n","training_generator = datagen.flow_from_directory(\n","    data_dir, # Path to the directory containing the training images\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size, # Load the images in batches of 32\n","    class_mode='categorical' # Set the class mode to categorical (since we have multiple classes)\n",")\n","training_samples, __ = train_test_split(training_generator, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["val_generator = ImageDataGenerator()\n","validation_generator = val_generator.flow_from_directory(\n","    data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode = 'categorical'\n",")\n","_, validation_samples = train_test_split(validation_generator, test_size=0.2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Therefore, out of the total 3670 image files belonging to 5 classes, we are using 2936 image files for training and 734 image files for validation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:42.970063Z","iopub.status.busy":"2023-04-20T14:16:42.967651Z","iopub.status.idle":"2023-04-20T14:16:42.975247Z","shell.execute_reply":"2023-04-20T14:16:42.974271Z","shell.execute_reply.started":"2023-04-20T14:16:42.970022Z"},"id":"AFl5dhA2G-pd","outputId":"e67c91df-c179-421c-8341-4b0bb103cdb5","trusted":true},"outputs":[],"source":["class_names = training_generator.class_names\n","print(class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:42.979061Z","iopub.status.busy":"2023-04-20T14:16:42.976608Z","iopub.status.idle":"2023-04-20T14:16:44.451501Z","shell.execute_reply":"2023-04-20T14:16:44.450569Z","shell.execute_reply.started":"2023-04-20T14:16:42.979020Z"},"id":"GxHmNYXFG-sO","outputId":"09844bc2-114f-4c6b-f880-7d3755ff3517","trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 12))\n","for images, labels in training_generator.take(1):\n","  for i in range(12):\n","    ax = plt.subplot(3, 4, i + 1)\n","    plt.imshow(images[i].numpy().astype(\"uint8\"))\n","    plt.title(class_names[labels[i]])\n","    plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:44.453921Z","iopub.status.busy":"2023-04-20T14:16:44.452776Z","iopub.status.idle":"2023-04-20T14:16:44.563094Z","shell.execute_reply":"2023-04-20T14:16:44.562103Z","shell.execute_reply.started":"2023-04-20T14:16:44.453878Z"},"id":"kuao7aGdHoOy","trusted":true},"outputs":[],"source":["num_classes = len(class_names)\n","\n","model = Sequential([\n","  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(num_classes,activation='softmax')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model2 = Sequential([\n","  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(num_classes,activation='softmax')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:44.566389Z","iopub.status.busy":"2023-04-20T14:16:44.565977Z","iopub.status.idle":"2023-04-20T14:16:44.582938Z","shell.execute_reply":"2023-04-20T14:16:44.581860Z","shell.execute_reply.started":"2023-04-20T14:16:44.566347Z"},"id":"oBerY4upHoRd","trusted":true},"outputs":[],"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:16:44.585211Z","iopub.status.busy":"2023-04-20T14:16:44.584799Z","iopub.status.idle":"2023-04-20T14:16:44.592488Z","shell.execute_reply":"2023-04-20T14:16:44.591579Z","shell.execute_reply.started":"2023-04-20T14:16:44.585171Z"},"id":"ha7amkdaHoUe","outputId":"3e988d44-e40b-4db5-bc5e-f714e4f31e68","trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-04-20T14:16:44.594724Z","iopub.status.busy":"2023-04-20T14:16:44.594111Z","iopub.status.idle":"2023-04-20T14:18:35.473413Z","shell.execute_reply":"2023-04-20T14:18:35.472309Z","shell.execute_reply.started":"2023-04-20T14:16:44.594684Z"},"id":"GAyyf--hHoXc","outputId":"3e5e508a-f0ca-4186-f275-1daf4a4cc79c","trusted":true},"outputs":[],"source":["epochs=15\n","history = model.fit(\n","  training_samples,\n","  validation_data=validation_samples,\n","  epochs=epochs\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:18:35.482236Z","iopub.status.busy":"2023-04-20T14:18:35.475376Z","iopub.status.idle":"2023-04-20T14:18:35.851738Z","shell.execute_reply":"2023-04-20T14:18:35.850705Z","shell.execute_reply.started":"2023-04-20T14:18:35.482154Z"},"id":"TzeI9PUSISk2","outputId":"a7f4eb1f-5ed5-405a-f3ea-1bd20b1fcdd2","trusted":true},"outputs":[],"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(12, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('model 1 Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('model 2 Training and Validation Loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:18:35.861362Z","iopub.status.busy":"2023-04-20T14:18:35.856895Z","iopub.status.idle":"2023-04-20T14:18:35.867638Z","shell.execute_reply":"2023-04-20T14:18:35.866725Z","shell.execute_reply.started":"2023-04-20T14:18:35.861317Z"},"id":"Imwy1iGQiE4T","trusted":true},"outputs":[],"source":["def predict_input_image(img):\n","  img_4d=img.reshape(-1,180,180,3)\n","  prediction=model.predict(img_4d)[0]\n","  return {class_names[i]: float(prediction[i]) for i in range(5)}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:18:35.875778Z","iopub.status.busy":"2023-04-20T14:18:35.874987Z","iopub.status.idle":"2023-04-20T14:18:37.203704Z","shell.execute_reply":"2023-04-20T14:18:37.202765Z","shell.execute_reply.started":"2023-04-20T14:18:35.875717Z"},"id":"HPvsN6KGISya","trusted":true},"outputs":[],"source":["import gradio as gr"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Before creating Gradio’s user interface, we must specify the size of the picture that Gradio’s input component will store. As shown in the code below, we are also providing the number of labeled classes in the image dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T14:18:37.206009Z","iopub.status.busy":"2023-04-20T14:18:37.205248Z","iopub.status.idle":"2023-04-20T14:19:14.807353Z","shell.execute_reply":"2023-04-20T14:19:14.806075Z","shell.execute_reply.started":"2023-04-20T14:18:37.205968Z"},"id":"PqKZB1OSx6nj","outputId":"ace72599-2783-4541-8bdd-2d2df49eafb5","trusted":true},"outputs":[],"source":["image = gr.inputs.Image(shape=(180,180))\n","label = gr.outputs.Label(num_top_classes=5)\n","\n","gr.Interface(fn=predict_input_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
